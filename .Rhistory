# ..............................................................................
summary_mem_accuracy <- fn_summarize_mem_accuracy(prep_data, vars)
list[prep_data, summary_mem_accuracy] <- fn_flagbad_mem_accuracy(summary_mem_accuracy, prep_data, vars)
# ..............................................................................
# Merge all summaries.
# ..............................................................................
summary_all <- reduce(list(summary_cat_accuracy, summary_cat_rt_target, summary_cat_rt_distractor, summary_mem_accuracy), full_join, by = c("participant", "typi_bin", "category"))
summary_all <- summary_all %>% mutate(bad_any = if_else(bad_cat_rt == 1 | bad_cat_acc == 1 | bad_mem_dp == 1, 1, 0))
prep_data <- prep_data %>% mutate(bad_any = if_else(bad_cat | bad_mem_dp == 1, 1, 0))
# ..............................................................................
# Remove participants if they have any kind of badness flag..
# ..............................................................................
bad_summary <- summary_all %>%
filter(bad_cat_rt == 1 | bad_cat_acc == 1 | bad_mem_dp == 1 | bad_catch == 1) %>%
select(participant, bad_cat_rt, bad_cat_acc, bad_mem_dp, bad_catch) %>%
distinct()
bad_singletrials <- prep_data %>%
filter(bad_cat == 1 | bad_mem_dp == 1| bad_catch == 1) %>%
select(participant, bad_cat, bad_mem_dp | bad_catch) %>%
distinct()
summary_all <- summary_all %>% anti_join(bad_summary, by = "participant")
prep_data   <- prep_data   %>% anti_join(bad_singletrials, by = "participant")
n_bad_cat <- bad_summary %>% filter(bad_cat_rt == 1 | bad_cat_acc == 1) %>% distinct(participant) %>% nrow()
n_bad_mem <- bad_summary %>% filter(bad_mem_dp == 1)                    %>% distinct(participant) %>% nrow()
n_bad_catch <- bad_summary %>% filter(bad_catch == 1)                    %>% distinct(participant) %>% nrow()
n_bad_any <- bad_summary %>% filter(bad_cat_rt == 1 | bad_cat_acc == 1| bad_catch == 1) %>% distinct(participant) %>% nrow()
# ------------------------------------------------------------------------------
# CATEGORIZATION accuracy
# ------------------------------------------------------------------------------
anova_cat_accuracy <- aov_ez(id="participant", dv="cat_dprime", summary_all %>%
filter(bad_any == 0), within = c("typi_bin", "category"), es = "pes")
nice(anova_cat_accuracy, es = "pes", "correction" = "GG")
anova_apa(anova_cat_accuracy, format="latex", es="petasq", sph_corr="greenhouse-geisser")
# Posthoc tests for interaction
post_cat_accuracy <- summary(pairs(emmeans(anova_cat_accuracy, pairwise ~ typi_bin|category), adjust = 'holm'))
print(post_cat_accuracy)
plot_cat_accuracy <- afex_plot(anova_cat_accuracy, x = "typi_bin",
trace = "category", error = "within",
mapping = c("shape", "color"), data_geom = geom_violin) +
labs(title = "Categorization\nAccuracy", x = "Typicality", y = "d'") +
# scale_y_continuous(limits = c(0, NA)) +
# theme_cowplot() +
theme_classic(base_size = 9) +
scale_color_discrete(labels = vars$categories) + guides(shape = "none") +
theme(legend.position="bottom")
print(plot_cat_accuracy)
# ------------------------------------------------------------------------------
# CATEGORIZATION response times.
# ------------------------------------------------------------------------------
anova_cat_rt <- aov_ez(id="participant", dv="cat_rt_target", summary_all %>%
filter(bad_any == 0), within = c("typi_bin", "category"), es = "pes")
nice(anova_cat_rt, es = "pes", "correction" = "GG")
anova_apa(anova_cat_rt, format="latex", es="petasq", sph_corr="greenhouse-geisser")
# Posthoc tests for interaction
post_cat_rt <- summary(pairs(emmeans(anova_cat_rt, pairwise ~ typi_bin|category), adjust = 'holm'))
print(post_cat_rt)
plot_cat_rt <- afex_plot(anova_cat_rt, x = "typi_bin",
trace = "category", error = "within",
mapping = c("shape", "color"), data_geom = geom_violin) +
labs(title = "Categorization\nRTs", x = "Typicality", y = "RT (ms)") +
#scale_y_continuous(limits = c(400, 1000)) +
theme_classic(base_size = 9) +
scale_color_discrete(labels = vars$categories) + guides(shape = "none") +
# theme_cowplot() +
theme(legend.position = "bottom")
# print(plot_cat_rt)
single_trial_rt <- prep_data %>% filter(task == "categorization") %>% filter(cond_cat == "target") %>% filter(cat_corr == 1) %>% filter(bad_any == 0) %>% filter(cat_rt < vars$cat_rt_max) %>%  filter(cat_rt > vars$cat_rt_min)
cat_rt <- single_trial_rt %>% group_by(typi_bin) %>% summarize( mean_cat_rt = mean(cat_rt, na.rm = TRUE), median_cat_rt = median(cat_rt, na.rm = TRUE) ) %>% ungroup()
library("paletteer")
plot_cat_singletrial_rts <- ggplot(single_trial_rt, aes(x = cat_rt, fill = typi_bin)) +
geom_density(alpha = 0.5) +
geom_vline(data = cat_rt, aes(xintercept = mean_cat_rt, color = typi_bin), linetype = "dotted", linewidth = 1.2, show.legend = FALSE) +
paletteer::scale_fill_paletteer_d("soilpalettes::podzol") +
paletteer::scale_color_paletteer_d("soilpalettes::podzol") +
labs(title = "Single trial RTs", x = "Response Time (ms)", y = "Density",fill='Typicality') +
#scale_colour_discrete(name = "Typicality") +
scale_x_continuous(limits = c(0, 1500)) +
theme_classic(base_size = 9) +
# theme_cowplot() +
theme(legend.position = c(0.8, 0.75))  # Correct legend position specification
single_trial_rt <- prep_data %>% filter(task == "categorization") %>% filter(cond_cat == "target") %>% filter(cat_corr == 1) %>% filter(bad_any == 0) %>% filter(cat_rt < vars$cat_rt_max) %>%  filter(cat_rt > vars$cat_rt_min)
cat_rt <- single_trial_rt %>% group_by(typi_bin) %>% summarize( mean_cat_rt = mean(cat_rt, na.rm = TRUE), median_cat_rt = median(cat_rt, na.rm = TRUE) ) %>% ungroup()
library("paletteer")
plot_cat_singletrial_rts <- ggplot(single_trial_rt, aes(x = cat_rt, fill = typi_bin)) +
geom_density(alpha = 0.5) +
geom_vline(data = cat_rt, aes(xintercept = mean_cat_rt, color = typi_bin), linetype = "dotted", linewidth = 1.2, show.legend = FALSE) +
paletteer::scale_fill_paletteer_d("soilpalettes::podzol") +
paletteer::scale_color_paletteer_d("soilpalettes::podzol") +
labs(title = "Single trial RTs", x = "Response Time (ms)", y = "Density",fill='Typicality') +
#scale_colour_discrete(name = "Typicality") +
scale_x_continuous(limits = c(0, 1500)) +
theme_classic(base_size = 9) +
# theme_cowplot() +
legend.position.inside = c(0.8, 0.75)  # Correct legend position specification
plot_cat_singletrial_rts <- ggplot(single_trial_rt, aes(x = cat_rt, fill = typi_bin)) +
geom_density(alpha = 0.5) +
geom_vline(data = cat_rt, aes(xintercept = mean_cat_rt, color = typi_bin), linetype = "dotted", linewidth = 1.2, show.legend = FALSE) +
paletteer::scale_fill_paletteer_d("soilpalettes::podzol") +
paletteer::scale_color_paletteer_d("soilpalettes::podzol") +
labs(title = "Single trial RTs", x = "Response Time (ms)", y = "Density",fill='Typicality') +
#scale_colour_discrete(name = "Typicality") +
scale_x_continuous(limits = c(0, 1500)) +
theme_classic(base_size = 9) +
# theme_cowplot() +
# legend.position.inside = c(0.8, 0.75)  # Correct legend position specification
```
single_trial_rt <- prep_data %>% filter(task == "categorization") %>% filter(cond_cat == "target") %>% filter(cat_corr == 1) %>% filter(bad_any == 0) %>% filter(cat_rt < vars$cat_rt_max) %>%  filter(cat_rt > vars$cat_rt_min)
cat_rt <- single_trial_rt %>% group_by(typi_bin) %>% summarize( mean_cat_rt = mean(cat_rt, na.rm = TRUE), median_cat_rt = median(cat_rt, na.rm = TRUE) ) %>% ungroup()
library("paletteer")
plot_cat_singletrial_rts <- ggplot(single_trial_rt, aes(x = cat_rt, fill = typi_bin)) +
geom_density(alpha = 0.5) +
geom_vline(data = cat_rt, aes(xintercept = mean_cat_rt, color = typi_bin), linetype = "dotted", linewidth = 1.2, show.legend = FALSE) +
paletteer::scale_fill_paletteer_d("soilpalettes::podzol") +
paletteer::scale_color_paletteer_d("soilpalettes::podzol") +
labs(title = "Single trial RTs", x = "Response Time (ms)", y = "Density",fill='Typicality') +
#scale_colour_discrete(name = "Typicality") +
scale_x_continuous(limits = c(0, 1500)) +
theme_classic(base_size = 9) \Ã¾+
single_trial_rt <- prep_data %>% filter(task == "categorization") %>% filter(cond_cat == "target") %>% filter(cat_corr == 1) %>% filter(bad_any == 0) %>% filter(cat_rt < vars$cat_rt_max) %>%  filter(cat_rt > vars$cat_rt_min)
cat_rt <- single_trial_rt %>% group_by(typi_bin) %>% summarize( mean_cat_rt = mean(cat_rt, na.rm = TRUE), median_cat_rt = median(cat_rt, na.rm = TRUE) ) %>% ungroup()
library("paletteer")
plot_cat_singletrial_rts <- ggplot(single_trial_rt, aes(x = cat_rt, fill = typi_bin)) +
geom_density(alpha = 0.5) +
geom_vline(data = cat_rt, aes(xintercept = mean_cat_rt, color = typi_bin), linetype = "dotted", linewidth = 1.2, show.legend = FALSE) +
paletteer::scale_fill_paletteer_d("soilpalettes::podzol") +
paletteer::scale_color_paletteer_d("soilpalettes::podzol") +
labs(title = "Single trial RTs", x = "Response Time (ms)", y = "Density",fill='Typicality') +
#scale_colour_discrete(name = "Typicality") +
scale_x_continuous(limits = c(0, 1500)) +
theme_classic(base_size = 9) #+
# theme_cowplot() +
# legend.position.inside = c(0.8, 0.75)  # Correct legend position specification
single_trial_rt <- prep_data %>% filter(task == "categorization") %>% filter(cond_cat == "target") %>% filter(cat_corr == 1) %>% filter(bad_any == 0) %>% filter(cat_rt < vars$cat_rt_max) %>%  filter(cat_rt > vars$cat_rt_min)
cat_rt <- single_trial_rt %>% group_by(typi_bin) %>% summarize( mean_cat_rt = mean(cat_rt, na.rm = TRUE), median_cat_rt = median(cat_rt, na.rm = TRUE) ) %>% ungroup()
library("paletteer")
plot_cat_singletrial_rts <- ggplot(single_trial_rt, aes(x = cat_rt, fill = typi_bin)) +
geom_density(alpha = 0.5) +
geom_vline(data = cat_rt, aes(xintercept = mean_cat_rt, color = typi_bin), linetype = "dotted", linewidth = 1.2, show.legend = FALSE) +
paletteer::scale_fill_paletteer_d("soilpalettes::podzol") +
paletteer::scale_color_paletteer_d("soilpalettes::podzol") +
labs(title = "Single trial RTs", x = "Response Time (ms)", y = "Density",fill='Typicality') +
#scale_colour_discrete(name = "Typicality") +
scale_x_continuous(limits = c(0, 1500)) +
theme_classic(base_size = 9) +
theme_cowplot() +
# legend.position.inside = c(0.8, 0.75)  # Correct legend position specification
single_trial_rt <- prep_data %>% filter(task == "categorization") %>% filter(cond_cat == "target") %>% filter(cat_corr == 1) %>% filter(bad_any == 0) %>% filter(cat_rt < vars$cat_rt_max) %>%  filter(cat_rt > vars$cat_rt_min)
cat_rt <- single_trial_rt %>% group_by(typi_bin) %>% summarize( mean_cat_rt = mean(cat_rt, na.rm = TRUE), median_cat_rt = median(cat_rt, na.rm = TRUE) ) %>% ungroup()
library("paletteer")
plot_cat_singletrial_rts <- ggplot(single_trial_rt, aes(x = cat_rt, fill = typi_bin)) +
geom_density(alpha = 0.5) +
geom_vline(data = cat_rt, aes(xintercept = mean_cat_rt, color = typi_bin), linetype = "dotted", linewidth = 1.2, show.legend = FALSE) +
paletteer::scale_fill_paletteer_d("soilpalettes::podzol") +
paletteer::scale_color_paletteer_d("soilpalettes::podzol") +
labs(title = "Single trial RTs", x = "Response Time (ms)", y = "Density",fill='Typicality') +
#scale_colour_discrete(name = "Typicality") +
scale_x_continuous(limits = c(0, 1500)) +
theme_classic(base_size = 9) +
theme_cowplot() #+
# legend.position.inside = c(0.8, 0.75)  # Correct legend position specification
library(ggpubr)
top_plots <- ggarrange(
plot_cat_accuracy, plot_cat_rt,
align = "h", labels = c("A", "B"),
common.legend = TRUE, legend="bottom"
)
plot_cat <- plot_grid(top_plots,
plot_cat_singletrial_rts,
labels = c('', 'C'), ncol = 1, label_size = 12, align = "l",
rel_heights = c(1.5, 1))
ggsave2("fig_cat.png", last_plot(), path=dirs$plots, bg="white", width=8.9, height=10, units="cm")
library(ggpubr)
top_plots <- ggarrange(
plot_cat_accuracy, plot_cat_rt,
align = "h", labels = c("A", "B"),
common.legend = TRUE, legend="bottom"
)
plot_cat <- plot_grid(top_plots,
plot_cat_singletrial_rts,
labels = c('', 'C'), ncol = 1, label_size = 12, align = "l",
rel_heights = c(1.5, 1))
ggsave2("fig_cat.png", last_plot(), path=dirs$plots, bg="white", width=8.9, height=10, units="cm")
# the variables mem_dprime and mem_crit refer to the conventional d' and c.
# the variables mem_dprime_conf and mem_crit_conf are computed weighted by confidence rating.
anova_mem_hitr <- aov_ez(id="participant", dv="mem_hitr", summary_all %>% filter(bad_any == 0), within = c("typi_bin", "category"))
nice(anova_mem_hitr, es = "pes", "correction" = "GG")
anova_mem_falr <- aov_ez(id="participant", dv="mem_falr", summary_all %>% filter(bad_any == 0), within = c("typi_bin", "category"))
nice(anova_mem_falr, es = "pes", "correction" = "GG")
anova_mem_acc <- aov_ez(id="participant", dv="mem_dprime", summary_all %>% filter(bad_any == 0), within = c("typi_bin", "category"))
nice(anova_mem_acc, es = "pes", "correction" = "GG")
anova_apa(anova_mem_acc, format="latex", es="petasq", sph_corr="greenhouse-geisser")
post_mem_acc <- summary(pairs(emmeans(anova_mem_acc, pairwise ~ typi_bin|category), adjust = 'holm'))
print(post_mem_acc)
anova_mem_bias <- aov_ez(id="participant", dv="mem_crit", summary_all %>% filter(bad_any == 0), within = c("typi_bin", "category"))
nice(anova_mem_bias, es = "pes", "correction" = "GG")
anova_apa(anova_mem_bias, format="latex", es="petasq", sph_corr="greenhouse-geisser")
print(emmeans(anova_mem_bias, pairwise ~ typi_bin))
print(emmeans(anova_mem_bias, pairwise ~ category))
print(emmeans(anova_mem_bias, pairwise ~ typi_bin|category))
# Posthoc tests for interaction
plot_mem_hitr <- afex_plot(anova_mem_hitr, x = "typi_bin", trace = "category", error = "within", mapping = c("shape", "color"), data_geom = geom_violin) +
labs(title = "Memory\naccuracy", x = "Typicality", y = "hit rate'") +
scale_y_continuous(limits = c(-0.5, 1.5)) +
theme_classic(base_size = 9) +
theme(plot.title = element_text(size=10)) +
theme(legend.position="none")
#print(plot_mem_hitr)
plot_mem_falr <- afex_plot(anova_mem_falr, x = "typi_bin", trace = "category", error = "within", mapping = c("shape", "color"), data_geom = geom_violin) +
labs(title = "Memory\naccuracy", x = "Typicality", y = "false alarm rate'") +
scale_y_continuous(limits = c(-0.5, 1.5)) +
theme_classic(base_size = 9) +
theme(plot.title = element_text(size=10)) +
theme(legend.position="none")
#print(plot_mem_falr)
plot_mem_accuracy <- afex_plot(anova_mem_acc, x = "typi_bin", trace = "category", error = "within", mapping = c("shape", "color"), data_geom = geom_violin) +
labs(title = "Memory\nAccuracy", x = "Typicality", y = "d'") +
#scale_y_continuous(limits = c(-0.5, 1.5)) +
theme_classic(base_size = 9) +
theme(plot.title = element_text(size=10)) +
theme(legend.position="none")
# print(plot_mem_accuracy)
plot_mem_bias <- afex_plot(anova_mem_bias, x = "typi_bin", trace = "category", error = "within", mapping = c("shape", "color"), data_geom = geom_violin) +
labs(title = "Memory\nBias", x = "Typicality", y = "Criterion") +
#scale_y_continuous(limits = c(0, NA)) +
theme_classic(base_size = 9) +
theme(plot.title = element_text(size=10)) +
theme(legend.position="none")
#print(plot_mem_bias)
plot_grid(plot_mem_hitr, plot_mem_falr, plot_mem_accuracy, plot_mem_bias, labels = "AUTO", label_size = 12, ncol = 2, align = "hv")
plot_mem <- plot_grid(plot_mem_accuracy, plot_mem_bias, labels = c("D", "E"), label_size = 12, ncol = 2, align = "hv")
plot_all <- plot_grid(plot_cat, plot_mem, nrow = 2, label_size = 12, align = "l",
rel_heights = c(2, 1))
print(plot_all)
ggsave2("fig_all.png", last_plot(), path=dirs$plots, bg="white", width=8.9, height=15, units="cm")
source(file.path(dirs$functions, "fn_summarize_image_data.R"))
library("viridis")
summary_img <- fn_summarize_image_data(prep_data, vars)
nice(anova_mem_hitr, es = "pes", "correction" = "GG")
anova_mem_falr <- aov_ez(id="participant", dv="mem_falr", summary_all %>% filter(bad_any == 0), within = c("typi_bin", "category"))
nice(anova_mem_falr, es = "pes", "correction" = "GG")
anova_mem_acc <- aov_ez(id="participant", dv="mem_dprime", summary_all %>% filter(bad_any == 0), within = c("typi_bin", "category"))
nice(anova_mem_acc, es = "pes", "correction" = "GG")
anova_apa(anova_mem_acc, format="latex", es="petasq", sph_corr="greenhouse-geisser")
post_mem_acc <- summary(pairs(emmeans(anova_mem_acc, pairwise ~ typi_bin|category), adjust = 'holm'))
print(post_mem_acc)
anova_mem_bias <- aov_ez(id="participant", dv="mem_crit", summary_all %>% filter(bad_any == 0), within = c("typi_bin", "category"))
nice(anova_mem_bias, es = "pes", "correction" = "GG")
anova_apa(anova_mem_bias, format="latex", es="petasq", sph_corr="greenhouse-geisser")
print(plot_all)
demographics_both   <- fn_get_demographics(data=all_data,    id="participant")
# ------------------------------------------------------------------------------
# Summarize demographic data.
# ------------------------------------------------------------------------------
source(file.path(dirs$functions, "fn_get_demographics.R"))
demographics_both   <- fn_get_demographics(data=all_data,    id="participant")
View(demographics_both)
# ------------------------------------------------------------------------------
# Summarize demographic data.
# ------------------------------------------------------------------------------
source(file.path(dirs$functions, "fn_get_demographics.R"))
demographics_both <- fn_get_demographics(data = all_data, id = "participant")
demographics <- data.frame()
# ------------------------------------------------------------------------------
# Summarize demographic data.
# ------------------------------------------------------------------------------
source(file.path(dirs$functions, "fn_get_demographics.R"))
demographics_both <- fn_get_demographics(data = all_data, id = "participant")
# ------------------------------------------------------------------------------
# Summarize demographic data.
# ------------------------------------------------------------------------------
source(file.path(dirs$functions, "fn_get_demographics.R"))
demographics <- fn_get_demographics(data = all_data, id = "participant")
# ------------------------------------------------------------------------------
# CATEGORIZATION accuracy
# ------------------------------------------------------------------------------
anova_cat_accuracy <- aov_ez(id="participant", dv="cat_dprime", summary_all %>%
filter(bad_any == 0), within = c("typi_bin", "category"), es = "pes")
nice(anova_cat_accuracy, es = "pes", "correction" = "GG")
anova_apa(anova_cat_accuracy, format="latex", es="petasq", sph_corr="greenhouse-geisser")
# Posthoc tests for interaction
post_cat_accuracy <- summary(pairs(emmeans(anova_cat_accuracy, pairwise ~ typi_bin|category), adjust = 'holm'))
print(post_cat_accuracy)
plot_cat_accuracy <- afex_plot(anova_cat_accuracy, x = "typi_bin",
trace = "category", error = "within",
mapping = c("shape", "color"), data_geom = geom_violin) +
labs(title = "Categorization\nAccuracy", x = "Typicality", y = "d'") +
# scale_y_continuous(limits = c(0, NA)) +
# theme_cowplot() +
theme_classic(base_size = 9) +
scale_color_discrete(labels = vars$categories) + guides(shape = "none") +
theme(legend.position="bottom")
print(plot_cat_accuracy)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                      <- list()
vars$exp_name             <- "scenecat_2.0"
vars$min_logfile_kbsize   <- 50 # some logfiles do not include all metadata (probably because the experiment was immediately interrupted). this makes the code crash. we need to exclude these files.
# We need to code where a given dataset was collected. This is not coded in
# the Psychopy logfiles, but we can infer it from certain columns that are unique
# to the Prague/Muenster version.
vars$place_strings       <- list(
"Alter"  = "Muenster",
"vpcode" = "Muenster",
"email"  = "Prague"
)
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames      <- c("Alter"       = "age",
"Geschlecht"  = "gender",
"Haendigkeit" = "handedness")
vars$columns_of_interest <- c("participant", "age", "gender", "handed", "place",
"task",
"target_cat", "cond_cat", "cat_key", "cat_corr", "cat_rt",
"cond_mem", "mem_response", "mem_perform",
"typicality", "conceptual", "perceptual",  "category", "stimulus"
)
# ATTENTION: when you first clone this repository, you need to edit the content
# of the file TEMPLATEsetpaths.R as follows:
#
# - Open the script and edit all the directory names to match your local directory structure.
# - Then save the script under setpath.R, i.e. omitting the "TEMPLATE" prefix.
#
# The rationale is that every user will have a different directory structure,
# but we do not want to push and pull everyone's local settings back and forth
# between each other. I have included the file "setpaths.R" in the .gitignore
# list, so your local setpaths.R script will not be tracked and synced by Git.
source("setpaths.R")
dirs <- setpaths()
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, vars, "SceneCat")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars, dirs)
# Read all logfiles and append the raw data.
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                      <- list()
vars$exp_name             <- "scenecat_2.0"
vars$min_logfile_kbsize   <- 50 # some logfiles do not include all metadata (probably because the experiment was immediately interrupted). this makes the code crash. we need to exclude these files.
# We need to code where a given dataset was collected. This is not coded in
# the Psychopy logfiles, but we can infer it from certain columns that are unique
# to the Prague/Muenster version.
vars$place_strings       <- list(
"Alter"  = "Muenster",
"vpcode" = "Muenster",
"email"  = "Prague"
)
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames      <- c("Alter"       = "age",
"Geschlecht"  = "gender",
"Haendigkeit" = "handedness")
vars$columns_of_interest <- c("participant", "age", "gender", "handed", "place",
"task",
"target_cat", "cond_cat", "cat_key", "cat_corr", "cat_rt",
"cond_mem", "mem_response", "mem_perform",
"typicality", "conceptual", "perceptual",  "category", "stimulus"
)
# ATTENTION: when you first clone this repository, you need to edit the content
# of the file TEMPLATEsetpaths.R as follows:
#
# - Open the script and edit all the directory names to match your local directory structure.
# - Then save the script under setpath.R, i.e. omitting the "TEMPLATE" prefix.
#
# The rationale is that every user will have a different directory structure,
# but we do not want to push and pull everyone's local settings back and forth
# between each other. I have included the file "setpaths.R" in the .gitignore
# list, so your local setpaths.R script will not be tracked and synced by Git.
source("setpaths.R")
dirs <- setpaths()
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, vars, "SceneCat")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars, dirs)
# Read all logfiles and append the raw data.
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
View(raw_data)
# ==============================================================================
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                      <- list()
vars$exp_name             <- "scenecat_2.0"
vars$min_logfile_kbsize   <- 50 # some logfiles do not include all metadata (probably because the experiment was immediately interrupted). this makes the code crash. we need to exclude these files.
# We need to code where a given dataset was collected. This is not coded in
# the Psychopy logfiles, but we can infer it from certain columns that are unique
# to the Prague/Muenster version.
vars$place_strings       <- list(
"Alter"  = "Muenster",
"vpcode" = "Muenster",
"email"  = "Prague"
)
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames      <- c("Alter"       = "age",
"Geschlecht"  = "gender",
"Haendigkeit" = "handedness")
vars$columns_of_interest <- c("participant", "age", "gender", "handed", "place",
"task",
"target_cat", "cond_cat", "cat_key", "cat_corr", "cat_rt",
"cond_mem", "mem_response", "mem_perform",
"typicality", "conceptual", "perceptual",  "category", "stimulus"
)
# ATTENTION: when you first clone this repository, you need to edit the content
# of the file TEMPLATEsetpaths.R as follows:
#
# - Open the script and edit all the directory names to match your local directory structure.
# - Then save the script under setpath.R, i.e. omitting the "TEMPLATE" prefix.
#
# The rationale is that every user will have a different directory structure,
# but we do not want to push and pull everyone's local settings back and forth
# between each other. I have included the file "setpaths.R" in the .gitignore
# list, so your local setpaths.R script will not be tracked and synced by Git.
source("setpaths.R")
dirs <- setpaths()
# === Read the log files. ======================================================
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, vars, "SceneCat")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars, dirs)
# Read all logfiles and append the raw data.
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
# Select only the data we are interested in a bring them into a coherent format.
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
# Select only the data we are interested in a bring them into a coherent format.
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
demographics_both[["n"]]
# ==============================================================================
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                      <- list()
vars$exp_name             <- "scenecat_2.0"
vars$min_logfile_kbsize   <- 50 # some logfiles do not include all metadata (probably because the experiment was immediately interrupted). this makes the code crash. we need to exclude these files.
# We need to code where a given dataset was collected. This is not coded in
# the Psychopy logfiles, but we can infer it from certain columns that are unique
# to the Prague/Muenster version.
vars$place_strings       <- list(
"Alter"  = "Muenster",
"vpcode" = "Muenster",
"email"  = "Prague"
)
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames      <- c("Alter"       = "age",
"Geschlecht"  = "gender",
"Haendigkeit" = "handedness")
vars$columns_of_interest <- c("participant", "age", "gender", "handed", "place",
"task",
"target_cat", "cond_cat", "cat_key", "cat_corr", "cat_rt",
"cond_mem", "mem_response", "mem_perform",
"typicality", "conceptual", "perceptual",  "category", "stimulus"
)
# ATTENTION: when you first clone this repository, you need to edit the content
# of the file TEMPLATEsetpaths.R as follows:
#
# - Open the script and edit all the directory names to match your local directory structure.
# - Then save the script under setpath.R, i.e. omitting the "TEMPLATE" prefix.
#
# The rationale is that every user will have a different directory structure,
# but we do not want to push and pull everyone's local settings back and forth
# between each other. I have included the file "setpaths.R" in the .gitignore
# list, so your local setpaths.R script will not be tracked and synced by Git.
source("setpaths.R")
dirs <- setpaths()
# === Read the log files. ======================================================
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, vars, "SceneCat")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars, dirs)
# Read all logfiles and append the raw data.
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
# Select only the data we are interested in a bring them into a coherent format.
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
View(all_data)
