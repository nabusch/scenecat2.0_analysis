total_count = total_count,
vpcode = vpcode,
stringsAsFactors = FALSE
)
# Append the row to the summary data
summary_data <- rbind(summary_data, summary_row)
index <- index + 1
}
View(summary_row)
# Create a row summarizing the data
summary_row <- data.frame(
index = index,
participant = participant,
Alter = Alter,
Geschlecht = Geschlecht,
Haendigkeit = Haendigkeit,
day = day,
time = time,
memory_count = memory_count,
categorization_count = categorization_count,
total_count = total_count,
vpcode = vpcode,
stringsAsFactors = FALSE
)
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
View(logfile_overview)
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. Also, the format is slightly different between the locale
# version and online version. We import these files and transform them into a
# data frame with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
vars                     <- list()
vars$main_path           <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
dirs <- list()
dirs$main       <- vars$main_path
dirs$functions  <- dirs$main
dirs$analysis   <- dirs$main
dirs$data       <- dirs$main
dirs$local      <- dirs$main
dirs$online     <- dirs$main
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
# Initialize an empty data frame to store results
summary_data <- data.frame()
# Loop over all files in the list
index <- 1
for (file_path in logfile_list) {
# Read the file
data <- read.csv(file_path)
# Extract metadata
ID          <- unique(data$participant)
Age         <- unique(data$Alter)
Gender      <- unique(data$Geschlecht)
Handedness  <- unique(data$Haendigkeit)
Date        <- unique(data$date)
SubjectCode <- data$vpcode[which.max(seq_along(data$vpcode))] # Get the value of vpcode from the last line
# Ensure date is properly parsed
date_parsed <- lubridate::ymd_hms(date)
day  <- format(date_parsed, "%Y-%m-%d")
time <- format(date_parsed, "%H:%M:%S")
# Count rows for memory and categorization tasks
n_mem_trials <- sum(data$task == "memory", na.rm = TRUE)
n_cat_trials <- sum(data$task == "categorization", na.rm = TRUE)
n_tot_trials <- n_mem_trials + n_cat_trials
# Create a row summarizing the data
summary_row <- data.frame(
Index        = index,
ID           = ID,
Age          = Age,
Gender       = Gender,
Handedness   = Handedness,
Day          = day,
Time         = time,
n_mem_trials = n_mem_trials,
n_cat_trials = n_cat_trials,
n_tot_trials = n_tot_trials,
SubjectCode  = SubjectCode,
Filename     = basename(file_path), # Add the filename of the CSV
stringsAsFactors = FALSE
)
# Append the row to the summary data
summary_data <- rbind(summary_data, summary_row)
index <- index + 1
}
# Read the file
data <- read.csv(file_path)
# Extract metadata
ID          <- unique(data$participant)
Age         <- unique(data$Alter)
Gender      <- unique(data$Geschlecht)
Handedness  <- unique(data$Haendigkeit)
Date        <- unique(data$date)
SubjectCode <- data$vpcode[which.max(seq_along(data$vpcode))] # Get the value of vpcode from the last line
# Ensure date is properly parsed
date_parsed <- lubridate::ymd_hms(date)
# Ensure date is properly parsed
date_parsed <- lubridate::ymd_hms(Date)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
View(logfile_overview)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. Also, the format is slightly different between the locale
# version and online version. We import these files and transform them into a
# data frame with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
vars                     <- list()
vars$main_path           <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
dirs <- list()
dirs$main       <- vars$main_path
dirs$functions  <- dirs$main
dirs$analysis   <- dirs$main
dirs$data       <- dirs$main
dirs$local      <- dirs$main
dirs$online     <- dirs$main
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
View(logfile_overview)
column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list)
vars                     <- list()
vars$main_path           <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
dirs <- list()
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. Also, the format is slightly different between the locale
# version and online version. We import these files and transform them into a
# data frame with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
vars                     <- list()
vars$main_path           <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
dirs <- list()
dirs$main       <- vars$main_path
dirs$functions  <- dirs$main
dirs$analysis   <- dirs$main
dirs$data       <- dirs$main
dirs$local      <- dirs$main
dirs$online     <- dirs$main
u
u
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
View(logfile_overview)
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
View(raw_data)
source("fn_import_format_logfiles.R")
all_data <- fn_import_format_logfiles(vars, raw_data)
source("fn_import_format_logfiles.R")
all_data <- fn_import_format_logfiles(vars, raw_data)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. Also, the format is slightly different between the locale
# version and online version. We import these files and transform them into a
# data frame with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
vars                     <- list()
vars$main_path           <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
dirs <- list()
dirs$main       <- vars$main_path
dirs$functions  <- dirs$main
dirs$analysis   <- dirs$main
dirs$data       <- dirs$main
dirs$local      <- dirs$main
dirs$online     <- dirs$main
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
source("fn_import_format_logfiles.R")
all_data <- fn_import_format_logfiles(vars, raw_data)
out_name = paste0("scenecat_", vars$version, "_", vars$flavor, "_cleandata.csv")
write.csv(all_data, file = file.path(dirs$data, out_name), row.names = FALSE)
cleandata_name = paste0("scenecat_", vars$version, "_", vars$flavor, "_cleandata.csv")
View(raw_data)
vars$exp_name            <- "scenecat_2.0"
overview_name = paste0(vars$exp_name, "_cleandata.csv")
write.csv(all_data, file = file.path(dirs$data, cleandata), row.names = FALSE)
overview_name = paste0(vars$exp_name, "_overview.csv")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
overview_name = paste0(vars$exp_name, "_overview.csv")
print(sprintf("Saving logfile overview to %s\n", overview_name))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                     <- list()
vars$exp_name            <- "scenecat_2.0"
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
# Where is all this stuff located?
dirs <- list()
dirs$main       <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
dirs$functions  <- paste0(dirs$main, "scenecat_analysis/functions/")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                     <- list()
vars$exp_name            <- "scenecat_2.0"
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
# Where is all this stuff located?
dirs <- list()
dirs$main       <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
dirs$functions  <- paste0(dirs$main, "/functions/")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
dirs
dirs$logfiles   <- paste0(dirs$main, "/logfiles/")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                     <- list()
vars$exp_name            <- "scenecat_2.0"
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
# Where is all this stuff located?
dirs <- list()
dirs$main       <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
dirs$functions  <- paste0(dirs$main, "/functions/")
dirs$logfiles   <- paste0(dirs$main, "/logfiles/")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
source("fn_import_format_logfiles.R")
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
cleandata_name = paste0("scenecat_", vars$version, "_", vars$flavor, "_cleandata.csv")
write.csv(all_data, file = file.path(dirs$main, cleandata), row.names = FALSE)
cleandata_name = paste0("scenecat_", vars$version, "_", vars$flavor, "_cleandata.csv")
write.csv(all_data, file = file.path(dirs$main, cleandata_name), row.names = FALSE)
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                     <- list()
vars$exp_name            <- "scenecat_2.0"
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
# Where is all this stuff located?
dirs <- list()
dirs$main       <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
dirs$functions  <- paste0(dirs$main, "/code/functions/")
dirs$logfiles   <- paste0(dirs$main, "/data/logfiles/")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Read all logfiles and append the raw data.
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
# Select only the data we are interested in a bring them into a coherent format.
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
# ==============================================================================
# Check to see how often each image was shown.
stimulus_counts <- all_data %>%
count(stimulus, name = "count") %>%
arrange(desc(count)) # Optional: sort by the count in descending order
# Display the result
stimulus_counts
# This script reads in the raw .csv files that were produced by Psychopy. These
# files have terrible formatting and include a lot of data that is not relevant
# for our analysis. We import these files and transform them into a data frame
# with one line per trial.
rm(list = ls(all.names = TRUE))
library(pacman)
p_load(dplyr, tidyr, stringr, readr)
# Define all variable decisions of this analysis.
vars                     <- list()
vars$exp_name            <- "scenecat_2.0"
# The German version of this experiment has some columns named in German. Wie
# need to rename these columns for consistency with the English version.
vars$column_renames <- c("Alter"       = "Age",
"Geschlecht"  = "Gender",
"Haendigkeit" = "Handedness")
vars$columns_of_interest <- c("stimulus", "correct_answer",
"task",
"target_cat", "cond_cat", "cond_mem", "category", "typicality",
"p_typicality", "r_typicality", "conceptual", "perceptual",
"n", "cat_key", "cat_corr", "cat_rt", "mem_response",
"participant", "age", "gender", "handed")
# Where is all this stuff located?
dirs <- list()
dirs$main       <- "C:/Users/nbusch/sciebo_box_projects/Projects/2024_scenecat2.0/pilot"
dirs$functions  <- paste0(dirs$main, "/code/scenecat2.0_analysis/functions/")
dirs$logfiles   <- paste0(dirs$main, "/data/logfiles/")
# Get a list of logfiles to process.
source(file.path(dirs$functions, "fn_list_logfiles.R"))
logfile_list <- fn_list_logfiles(dirs, "SceneCat_2023")
# Get an overview of our datasets.
source(file.path(dirs$functions, "fn_logfile_overview.R"))
logfile_overview <- fn_logfile_overview(logfile_list, vars)
# Read all logfiles and append the raw data.
source(file.path(dirs$functions, "fn_import_read_logfiles.R"))
raw_data <- fn_import_read_logfiles(logfile_list, vars)
# Select only the data we are interested in a bring them into a coherent format.
source(file.path(dirs$functions, "fn_import_format_logfiles.R"))
all_data <- fn_import_format_logfiles(vars, raw_data)
